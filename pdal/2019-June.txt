From karln at surdex.com  Tue Jun  4 15:07:31 2019
From: karln at surdex.com (Karl North)
Date: Tue, 4 Jun 2019 22:07:31 +0000
Subject: [pdal] tweaking parameters in filters.smrf
Message-ID: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>

Greetings PDAL'ers.

I'm new to PDAL, and have recently begun the testing of a PDAL pipeline in hopes of improving an existing automated workflow which uses a TerraScan macro to classify ground points in raw Lidar point clouds.  My pipeline is based on the SMRF filter.

By including the ELM and OUTLIER filters, and then juggling the cell size, scalar, slope, threshold, widow size and the cut grid parameters in the SMRF filter, I can achieve a final point cloud that is mostly equivalent to the TSCAN result in many terrain/vegetation/feature scenarios.  Of course, I would like to use PDAL to surpass the TSCAN results.  The main issue that I currently have with my PDAL result is the presence of too much high frequency "noise" visible in the surface defined by the ground classified points.  A lesser issue is the delicate balance, when using the cut grid parameter to help eliminate building points, between the removal of building features and preserving sufficient terrain detail.

I should point out that we've invested several years (off and on) in tweaking our TSCAN macro with the help of paid support staff to achieve the current excellent result, and that the macro includes 40+ individual steps to achieve this result.  In comparison, to date we have only devoted a couple of weeks to testing/tweaking the PDAL filter parameters.

I've searched on-line for tutorials/suggestions/experiences that users have had with tweaking the SMRF parameters in various terrain types, vegetation density/types, and cultural feature density/types but have really not found a definitive guide.

Is there anyone out there on the mailing list that can suggest such write-ups, or would be willing to share their insights?

Perhaps there are other (as yet undiscovered) PDAL filters that I might include in my pipeline either before or after SMRF that would be better suited to the remaining cleanup than tweaking the SMRF parameters themselves.

I can share sample LAZ data illustrating a SMRF-vs-TSCAN comparison of current my state-of-the-art, if this will help clarify the current issue(s).  To do so, I could use some guidance on reasonable limits on file size for sharing such a sample.

Thanks in advance for any/all suggestions.

Karl
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190604/379503b3/attachment.html>

From brad.chambers at gmail.com  Fri Jun  7 09:29:01 2019
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Fri, 7 Jun 2019 12:29:01 -0400
Subject: [pdal] tweaking parameters in filters.smrf
In-Reply-To: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
References: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
Message-ID: <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>

Karl,

On Fri, Jun 7, 2019 at 12:09 PM Karl North <karln at surdex.com> wrote:

> The main issue that I currently have with my PDAL result is the presence
> of too much high frequency ‚Äúnoise‚Äù visible in the surface defined by the
> ground classified points.  A lesser issue is the delicate balance, when
> using the cut grid parameter to help eliminate building points, between the
> removal of building features and preserving sufficient terrain detail.
>

The issue you've mentioned with and without cut is well known. It would be
interesting to hear more about what you are seeing with the high frequency
noise though.


> Is there anyone out there on the mailing list that can suggest such
> write-ups, or would be willing to share their insights?
>

I don't know of any write-ups other than the original paper. The original
author also has his MATLAB code on GitHub (
https://github.com/thomaspingel/neilpy), though I don't recall that there
are any hints on what parameters to tweak for specific environments.


> Perhaps there are other (as yet undiscovered) PDAL filters that I might
> include in my pipeline either before or after SMRF that would be better
> suited to the remaining cleanup than tweaking the SMRF parameters
> themselves.
>

One thing that comes to mind, though it would take some experimentation,
would be to run a cluster filter (
https://pdal.io/stages/filters.cluster.html#filters-cluster) after SMRF and
then to filter out clusters that were small. I'd maybe use this without cut
to find those roof segments that got left behind and may end up as their
own clusters.


> I can share sample LAZ data illustrating a SMRF-vs-TSCAN comparison of
> current my state-of-the-art, if this will help clarify the current
> issue(s).  To do so, I could use some guidance on reasonable limits on file
> size for sharing such a sample.
>

It would certainly be interesting to see the data. Other users in the past
have posted to Google Drive, Dropbox, or similar.

Brad
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190607/fc08ea05/attachment.html>

From karln at surdex.com  Wed Jun 12 07:36:37 2019
From: karln at surdex.com (Karl North)
Date: Wed, 12 Jun 2019 14:36:37 +0000
Subject: [pdal] tweaking parameters in filters.smrf
In-Reply-To: <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>
References: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
 <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>
Message-ID: <BN7PR17MB208185CCF60B683B400C518EC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>

Brad:

Thanks for the suggestions.

I‚Äôve done some reading and begun playing around with the cluster filter.  One problem is that I‚Äôm new enough to PDAL that I cannot find a way to add/define a dimension and store the cluster ID into either LAS or LAZ format on output.  I think it should be possible to just hijack an existing field in the point data records for current testing purposes.  Does this sound possible?  I‚Äôm floundering a bit trying to find an example of something similar.  Can you point me in the right direction?

I can get a BPF output, but currently have no way to review the result.  I‚Äôm now downloading 64-bit QT Reader, after finding a thread by HoBu saying that this viewer would work for a quick review.

I‚Äôve also tried using pdal translate to convert the BPF to LAS, but cannot find any trace of the ClusterID in the resulting LAS file.

Thanks for any and all assistance,

Karl


From: Bradley Chambers <brad.chambers at gmail.com>
Sent: Friday, June 7, 2019 11:29 AM
To: Karl North <karln at surdex.com>
Cc: pdal at lists.osgeo.org
Subject: Re: [pdal] tweaking parameters in filters.smrf

Karl,

On Fri, Jun 7, 2019 at 12:09 PM Karl North <karln at surdex.com<mailto:karln at surdex.com>> wrote:
The main issue that I currently have with my PDAL result is the presence of too much high frequency ‚Äúnoise‚Äù visible in the surface defined by the ground classified points.  A lesser issue is the delicate balance, when using the cut grid parameter to help eliminate building points, between the removal of building features and preserving sufficient terrain detail.

The issue you've mentioned with and without cut is well known. It would be interesting to hear more about what you are seeing with the high frequency noise though.

Is there anyone out there on the mailing list that can suggest such write-ups, or would be willing to share their insights?

I don't know of any write-ups other than the original paper. The original author also has his MATLAB code on GitHub (https://github.com/thomaspingel/neilpy<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fthomaspingel%2Fneilpy&data=02%7C01%7C%7C35f7a44a37464bc883b508d6eb65467b%7Cbf4323beeac04c8eb466c7924493cbee%7C0%7C1%7C636955217559063804&sdata=xQBCVsQE1yDqpbQ1PKAcVye54Atp8s3H2vY6854qdYU%3D&reserved=0>), though I don't recall that there are any hints on what parameters to tweak for specific environments.

Perhaps there are other (as yet undiscovered) PDAL filters that I might include in my pipeline either before or after SMRF that would be better suited to the remaining cleanup than tweaking the SMRF parameters themselves.

One thing that comes to mind, though it would take some experimentation, would be to run a cluster filter (https://pdal.io/stages/filters.cluster.html#filters-cluster<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpdal.io%2Fstages%2Ffilters.cluster.html%23filters-cluster&data=02%7C01%7C%7C35f7a44a37464bc883b508d6eb65467b%7Cbf4323beeac04c8eb466c7924493cbee%7C0%7C1%7C636955217559063804&sdata=Ot3hDXkA39602%2FrlxqvummbpIRBkd1xB9mPvl%2BuikdA%3D&reserved=0>) after SMRF and then to filter out clusters that were small. I'd maybe use this without cut to find those roof segments that got left behind and may end up as their own clusters.

I can share sample LAZ data illustrating a SMRF-vs-TSCAN comparison of current my state-of-the-art, if this will help clarify the current issue(s).  To do so, I could use some guidance on reasonable limits on file size for sharing such a sample.

It would certainly be interesting to see the data. Other users in the past have posted to Google Drive, Dropbox, or similar.

Brad
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190612/66838ed4/attachment.html>

From howard at hobu.co  Wed Jun 12 07:40:58 2019
From: howard at hobu.co (Howard Butler)
Date: Wed, 12 Jun 2019 09:40:58 -0500
Subject: [pdal] tweaking parameters in filters.smrf
In-Reply-To: <BN7PR17MB208185CCF60B683B400C518EC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>
References: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
 <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>
 <BN7PR17MB208185CCF60B683B400C518EC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>
Message-ID: <1EB71ADE-451D-4320-A7BE-8932593647A7@hobu.co>



> On Jun 12, 2019, at 9:36 AM, Karl North <karln at surdex.com> wrote:
> 
> Brad:
>  
> Thanks for the suggestions.
>  
> I‚Äôve done some reading and begun playing around with the cluster filter.  One problem is that I‚Äôm new enough to PDAL that I cannot find a way to add/define a dimension and store the cluster ID into either LAS or LAZ format on output.  I think it should be possible to just hijack an existing field in the point data records for current testing purposes.  Does this sound possible?  I‚Äôm floundering a bit trying to find an example of something similar.  Can you point me in the right direction?

Use the filters.ferry to copy ClusterID => PointSourceId downstream of your filters.cluster invocation.

https://pdal.io/stages/filters.ferry.html <https://pdal.io/stages/filters.ferry.html>


> I can get a BPF output, but currently have no way to review the result.  I‚Äôm now downloading 64-bit QT Reader, after finding a thread by HoBu saying that this viewer would work for a quick review.

I don't know if that is still viable.

You can also write to LAS with extra bytes

--writers.las.extra_dims=ClusterID

but you'll need something that can view extra LAS dimensions. 


Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190612/228fd745/attachment-0001.html>

From karln at surdex.com  Wed Jun 12 07:46:11 2019
From: karln at surdex.com (Karl North)
Date: Wed, 12 Jun 2019 14:46:11 +0000
Subject: [pdal] tweaking parameters in filters.smrf
In-Reply-To: <1EB71ADE-451D-4320-A7BE-8932593647A7@hobu.co>
References: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
 <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>
 <BN7PR17MB208185CCF60B683B400C518EC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>
 <1EB71ADE-451D-4320-A7BE-8932593647A7@hobu.co>
Message-ID: <BN7PR17MB208145E459CE31BAFE70029BC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>

Howard:

Excellent input.  Thanks.  I‚Äôll first check into using ‚Äúferry‚Äù to copy ClusterID into the LAS, and then look into adding/viewing extra dimensions in LAS/LAZ in my current software options.

QT Reader, by the way, was able to load the BPF file but didn‚Äôt make it immediately obvious how I might view the cluster ID.  This is, of course, and about 5 minutes of experience‚Ä¶  üòä

Karl


From: Howard Butler <howard at hobu.co>
Sent: Wednesday, June 12, 2019 9:41 AM
To: Karl North <karln at surdex.com>
Cc: Bradley Chambers <brad.chambers at gmail.com>; pdal at lists.osgeo.org
Subject: Re: [pdal] tweaking parameters in filters.smrf




On Jun 12, 2019, at 9:36 AM, Karl North <karln at surdex.com<mailto:karln at surdex.com>> wrote:

Brad:

Thanks for the suggestions.

I‚Äôve done some reading and begun playing around with the cluster filter.  One problem is that I‚Äôm new enough to PDAL that I cannot find a way to add/define a dimension and store the cluster ID into either LAS or LAZ format on output.  I think it should be possible to just hijack an existing field in the point data records for current testing purposes.  Does this sound possible?  I‚Äôm floundering a bit trying to find an example of something similar.  Can you point me in the right direction?

Use the filters.ferry to copy ClusterID => PointSourceId downstream of your filters.cluster invocation.

https://pdal.io/stages/filters.ferry.html<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpdal.io%2Fstages%2Ffilters.ferry.html&data=02%7C01%7C%7C5dc2119c10ca44f84e9008d6ef43fd22%7Cbf4323beeac04c8eb466c7924493cbee%7C0%7C0%7C636959472628150563&sdata=hKaN0thXKKf7fE%2F5nqkAZcSq8YMCR26WM7xkkz5IINI%3D&reserved=0>



I can get a BPF output, but currently have no way to review the result.  I‚Äôm now downloading 64-bit QT Reader, after finding a thread by HoBu saying that this viewer would work for a quick review.

I don't know if that is still viable.

You can also write to LAS with extra bytes

--writers.las.extra_dims=ClusterID

but you'll need something that can view extra LAS dimensions.


Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190612/49a44baf/attachment.html>

From karln at surdex.com  Wed Jun 12 11:41:02 2019
From: karln at surdex.com (Karl North)
Date: Wed, 12 Jun 2019 18:41:02 +0000
Subject: [pdal] tweaking parameters in filters.smrf
In-Reply-To: <1EB71ADE-451D-4320-A7BE-8932593647A7@hobu.co>
References: <BN7PR17MB2081EABA47E288EFD3AC5D19C2150@BN7PR17MB2081.namprd17.prod.outlook.com>
 <CAJyqqPweYo1Ztu1=nj-hKfrq=-QQrNPosS2Fq7t3q2PAe2b0PA@mail.gmail.com>
 <BN7PR17MB208185CCF60B683B400C518EC2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>
 <1EB71ADE-451D-4320-A7BE-8932593647A7@hobu.co>
Message-ID: <BN7PR17MB208197E53C44997302547585C2EC0@BN7PR17MB2081.namprd17.prod.outlook.com>

Moving along here, and have encountered a new question‚Ä¶

I‚Äôm getting some promising results from filters.cluster but would certainly like to be able to apply this filter ( and others ) multiple times with different settings while using writers.las after each filter so that I can review the progress of the overall pipeline processing after each step completes.

Is there a way to get my pipeline to write a LAS after each of the steps/filters?  I‚Äôd like to save interim results for review, but cannot find a good example in the docs or in the list archive.



From: Howard Butler <howard at hobu.co>
Sent: Wednesday, June 12, 2019 9:41 AM
To: Karl North <karln at surdex.com>
Cc: Bradley Chambers <brad.chambers at gmail.com>; pdal at lists.osgeo.org
Subject: Re: [pdal] tweaking parameters in filters.smrf




On Jun 12, 2019, at 9:36 AM, Karl North <karln at surdex.com<mailto:karln at surdex.com>> wrote:

Brad:

Thanks for the suggestions.

I‚Äôve done some reading and begun playing around with the cluster filter.  One problem is that I‚Äôm new enough to PDAL that I cannot find a way to add/define a dimension and store the cluster ID into either LAS or LAZ format on output.  I think it should be possible to just hijack an existing field in the point data records for current testing purposes.  Does this sound possible?  I‚Äôm floundering a bit trying to find an example of something similar.  Can you point me in the right direction?

Use the filters.ferry to copy ClusterID => PointSourceId downstream of your filters.cluster invocation.

https://pdal.io/stages/filters.ferry.html<https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpdal.io%2Fstages%2Ffilters.ferry.html&data=02%7C01%7C%7C5dc2119c10ca44f84e9008d6ef43fd22%7Cbf4323beeac04c8eb466c7924493cbee%7C0%7C0%7C636959472628150563&sdata=hKaN0thXKKf7fE%2F5nqkAZcSq8YMCR26WM7xkkz5IINI%3D&reserved=0>



I can get a BPF output, but currently have no way to review the result.  I‚Äôm now downloading 64-bit QT Reader, after finding a thread by HoBu saying that this viewer would work for a quick review.

I don't know if that is still viable.

You can also write to LAS with extra bytes

--writers.las.extra_dims=ClusterID

but you'll need something that can view extra LAS dimensions.


Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190612/d43fa30f/attachment-0001.html>

From pt at masseranolabs.com  Thu Jun 13 04:40:18 2019
From: pt at masseranolabs.com (Piero Toffanin)
Date: Thu, 13 Jun 2019 07:40:18 -0400
Subject: [pdal] Does Entwine support distributed builds?
Message-ID: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>

Hi there,

I have a question regarding the usage of Entwine and was hoping somebody 
could help me? The use case is merging point clouds that have been 
generated on different machines. Each of these point clouds is part to 
the same final dataset. Entwine works great with the current workflow:

entwine scan -i a.las b.las ... -o output/

for i in {a, b, ... }

 ¬†¬†¬† entwine build -i output/scan.json -o output/ --run 1

The "--run 1" is done to lower the memory usage. On small datasets 
runtime is excellent, but with more models the runtime starts to 
increase quite a bit. I'm looking specifically to see if there are ways 
to speed the generation of the EPT index. In particular, since I 
generate the various LAS files on different machines, I was wondering if 
there was a way to let each machine contribute its part of the index 
from the individual LAS files (such index mapped to a network location) 
or if a workflow is supported in which each machine can build its own 
EPT index and then merge all EPT indexes into one? I don't think this is 
possible, but wanted to check.

Thank you for any help,

-Piero


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190613/5ad9c92f/attachment.html>

From connor at hobu.co  Thu Jun 13 07:43:35 2019
From: connor at hobu.co (Connor Manning)
Date: Thu, 13 Jun 2019 09:43:35 -0500
Subject: [pdal] Does Entwine support distributed builds?
In-Reply-To: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
References: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
Message-ID: <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>

The `subset` option lets each iteration of the build run a spatially
distinct region, which can be trivially merged afterward, which sounds like
what you're after.  Another option could be to simply use multiple indexes
- potree can accept multiple input EPT sources, and a PDAL pipeline may
have multiple EPT readers.

On Thu, Jun 13, 2019 at 6:46 AM Piero Toffanin <pt at masseranolabs.com> wrote:

> Hi there,
>
> I have a question regarding the usage of Entwine and was hoping somebody
> could help me? The use case is merging point clouds that have been
> generated on different machines. Each of these point clouds is part to the
> same final dataset. Entwine works great with the current workflow:
>
> entwine scan -i a.las b.las ... -o output/
>
> for i in {a, b, ... }
>
>     entwine build -i output/scan.json -o output/ --run 1
>
> The "--run 1" is done to lower the memory usage. On small datasets runtime
> is excellent, but with more models the runtime starts to increase quite a
> bit. I'm looking specifically to see if there are ways to speed the
> generation of the EPT index. In particular, since I generate the various
> LAS files on different machines, I was wondering if there was a way to let
> each machine contribute its part of the index from the individual LAS files
> (such index mapped to a network location) or if a workflow is supported in
> which each machine can build its own EPT index and then merge all EPT
> indexes into one? I don't think this is possible, but wanted to check.
>
> Thank you for any help,
>
> -Piero
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190613/f5b7eab6/attachment.html>

From pt at masseranolabs.com  Thu Jun 13 08:16:31 2019
From: pt at masseranolabs.com (Piero Toffanin)
Date: Thu, 13 Jun 2019 11:16:31 -0400
Subject: [pdal] Does Entwine support distributed builds?
In-Reply-To: <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>
References: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
 <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>
Message-ID: <b0ee797b-2a96-f8a7-62dc-40a88c298d42@masseranolabs.com>

Hey Connor,

thanks for the reply. I have looked at the subset option and I think it 
would work well for the case where I have already computed all the 
models. For example if I have a folder with:

1.las
2.las
...

Then I could spin four machines and do:

1] entwine build -i 1.las 2.las --subset 1 4 -o out1
2] entwine build -i 1.las 2.las --subset 2 4 -o out2
3] entwine build -i 1.las 2.las --subset 3 4 -o out3
4] entwine build -i 1.las 2.las --subset 4 4 -o out4

Then merge the results. I've noticed two things with this. It seemed 
that as the number of input files increased, the memory and time 
required to create each subset seemed increased also (that's why I opted 
to use scan + build --run 1). The second is that I need to wait for all 
point clouds to be available (both 1.las and 2.las need to be available 
before I can start processing them).

I wanted to rule out whether it was possible to do something like (on 
two separate machines):

1] entwine build -i 1.las -o out1
2] entwine build -i 2.las -o out2

And then merge the resulting EPT indexes into a "global" one:

entwine merge -i out1 out2 -o merged

But I don't think it's possible, correct?

-Piero



On 6/13/19 10:43 AM, Connor Manning wrote:
> The `subset` option lets each iteration of the build run a spatially 
> distinct region, which can be trivially merged afterward, which sounds 
> like what you're after.¬† Another option could be to simply use 
> multiple indexes - potree can accept multiple input EPT sources, and a 
> PDAL pipeline may have multiple EPT readers.
>
> On Thu, Jun 13, 2019 at 6:46 AM Piero Toffanin <pt at masseranolabs.com 
> <mailto:pt at masseranolabs.com>> wrote:
>
>     Hi there,
>
>     I have a question regarding the usage of Entwine and was hoping
>     somebody could help me? The use case is merging point clouds that
>     have been generated on different machines. Each of these point
>     clouds is part to the same final dataset. Entwine works great with
>     the current workflow:
>
>     entwine scan -i a.las b.las ... -o output/
>
>     for i in {a, b, ... }
>
>     ¬†¬†¬† entwine build -i output/scan.json -o output/ --run 1
>
>     The "--run 1" is done to lower the memory usage. On small datasets
>     runtime is excellent, but with more models the runtime starts to
>     increase quite a bit. I'm looking specifically to see if there are
>     ways to speed the generation of the EPT index. In particular,
>     since I generate the various LAS files on different machines, I
>     was wondering if there was a way to let each machine contribute
>     its part of the index from the individual LAS files (such index
>     mapped to a network location) or if a workflow is supported in
>     which each machine can build its own EPT index and then merge all
>     EPT indexes into one? I don't think this is possible, but wanted
>     to check.
>
>     Thank you for any help,
>
>     -Piero
>
>
>     _______________________________________________
>     pdal mailing list
>     pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>
>     https://lists.osgeo.org/mailman/listinfo/pdal
>
-- 

*Piero Toffanin*
Drone Solutions Engineer

masseranolabs.com <https://www.masseranolabs.com>
piero.dev <https://www.piero.dev>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190613/d61898ef/attachment.html>

From connor at hobu.co  Thu Jun 13 08:39:13 2019
From: connor at hobu.co (Connor Manning)
Date: Thu, 13 Jun 2019 10:39:13 -0500
Subject: [pdal] Does Entwine support distributed builds?
In-Reply-To: <b0ee797b-2a96-f8a7-62dc-40a88c298d42@masseranolabs.com>
References: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
 <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>
 <b0ee797b-2a96-f8a7-62dc-40a88c298d42@masseranolabs.com>
Message-ID: <CAO=FyjJ8b8onyeebg2uhDkeOXu4azuH_05ZTLzxZ0Um4mKTs0g@mail.gmail.com>

Correct - that is not possible.

On Thu, Jun 13, 2019 at 10:16 AM Piero Toffanin <pt at masseranolabs.com>
wrote:

> Hey Connor,
>
> thanks for the reply. I have looked at the subset option and I think it
> would work well for the case where I have already computed all the models.
> For example if I have a folder with:
>
> 1.las
> 2.las
> ...
>
> Then I could spin four machines and do:
>
> 1] entwine build -i 1.las 2.las --subset 1 4 -o out1
> 2] entwine build -i 1.las 2.las --subset 2 4 -o out2
> 3] entwine build -i 1.las 2.las --subset 3 4 -o out3
> 4] entwine build -i 1.las 2.las --subset 4 4 -o out4
>
> Then merge the results. I've noticed two things with this. It seemed that
> as the number of input files increased, the memory and time required to
> create each subset seemed increased also (that's why I opted to use scan +
> build --run 1). The second is that I need to wait for all point clouds to
> be available (both 1.las and 2.las need to be available before I can start
> processing them).
>
> I wanted to rule out whether it was possible to do something like (on two
> separate machines):
>
> 1] entwine build -i 1.las -o out1
> 2] entwine build -i 2.las -o out2
>
> And then merge the resulting EPT indexes into a "global" one:
>
> entwine merge -i out1 out2 -o merged
>
> But I don't think it's possible, correct?
>
> -Piero
>
>
> On 6/13/19 10:43 AM, Connor Manning wrote:
>
> The `subset` option lets each iteration of the build run a spatially
> distinct region, which can be trivially merged afterward, which sounds like
> what you're after.  Another option could be to simply use multiple indexes
> - potree can accept multiple input EPT sources, and a PDAL pipeline may
> have multiple EPT readers.
>
> On Thu, Jun 13, 2019 at 6:46 AM Piero Toffanin <pt at masseranolabs.com>
> wrote:
>
> Hi there,
>
> I have a question regarding the usage of Entwine and was hoping somebody
> could help me? The use case is merging point clouds that have been
> generated on different machines. Each of these point clouds is part to the
> same final dataset. Entwine works great with the current workflow:
>
> entwine scan -i a.las b.las ... -o output/
>
> for i in {a, b, ... }
>
>     entwine build -i output/scan.json -o output/ --run 1
>
> The "--run 1" is done to lower the memory usage. On small datasets runtime
> is excellent, but with more models the runtime starts to increase quite a
> bit. I'm looking specifically to see if there are ways to speed the
> generation of the EPT index. In particular, since I generate the various
> LAS files on different machines, I was wondering if there was a way to let
> each machine contribute its part of the index from the individual LAS files
> (such index mapped to a network location) or if a workflow is supported in
> which each machine can build its own EPT index and then merge all EPT
> indexes into one? I don't think this is possible, but wanted to check.
>
> Thank you for any help,
>
> -Piero
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
> --
>
> *Piero Toffanin*
> Drone Solutions Engineer
>
> masseranolabs.com <https://www.masseranolabs.com>
> piero.dev <https://www.piero.dev>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190613/dc0e1692/attachment-0001.html>

From pt at masseranolabs.com  Thu Jun 13 08:56:58 2019
From: pt at masseranolabs.com (Piero Toffanin)
Date: Thu, 13 Jun 2019 11:56:58 -0400
Subject: [pdal] Does Entwine support distributed builds?
In-Reply-To: <CAO=FyjJ8b8onyeebg2uhDkeOXu4azuH_05ZTLzxZ0Um4mKTs0g@mail.gmail.com>
References: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
 <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>
 <b0ee797b-2a96-f8a7-62dc-40a88c298d42@masseranolabs.com>
 <CAO=FyjJ8b8onyeebg2uhDkeOXu4azuH_05ZTLzxZ0Um4mKTs0g@mail.gmail.com>
Message-ID: <2d032f04-7c55-cf2d-e59e-4c15de23bff2@masseranolabs.com>

Thanks, suspected that was the case but wanted to confirm.

In regard to building subsets, is there an advantage to using "entwine 
scan" vs. the input files directly to "entwine build" in terms of 
performance (or is scan a simple utility to simplify finding datasets 
within a folder)?

Are there any tips or tricks that I should be aware of in terms of 
memory usage when building using subset? For example, is it memory 
efficient to do:

entwine build -i 1.las 2.las [...] 399.las 400.las --subset 1 64 -o out1

?

As compared to perhaps running 400 times:

entwine build -i 1.las 2.las [...] 399.las 400.las --subset 1 64 -o out1 
--run 1

?

Sorry for all the questions!

On 6/13/19 11:39 AM, Connor Manning wrote:
> Correct - that is not possible.
>
> On Thu, Jun 13, 2019 at 10:16 AM Piero Toffanin <pt at masseranolabs.com 
> <mailto:pt at masseranolabs.com>> wrote:
>
>     Hey Connor,
>
>     thanks for the reply. I have looked at the subset option and I
>     think it would work well for the case where I have already
>     computed all the models. For example if I have a folder with:
>
>     1.las
>     2.las
>     ...
>
>     Then I could spin four machines and do:
>
>     1] entwine build -i 1.las 2.las --subset 1 4 -o out1
>     2] entwine build -i 1.las 2.las --subset 2 4 -o out2
>     3] entwine build -i 1.las 2.las --subset 3 4 -o out3
>     4] entwine build -i 1.las 2.las --subset 4 4 -o out4
>
>     Then merge the results. I've noticed two things with this. It
>     seemed that as the number of input files increased, the memory and
>     time required to create each subset seemed increased also (that's
>     why I opted to use scan + build --run 1). The second is that I
>     need to wait for all point clouds to be available (both 1.las and
>     2.las need to be available before I can start processing them).
>
>     I wanted to rule out whether it was possible to do something like
>     (on two separate machines):
>
>     1] entwine build -i 1.las -o out1
>     2] entwine build -i 2.las -o out2
>
>     And then merge the resulting EPT indexes into a "global" one:
>
>     entwine merge -i out1 out2 -o merged
>
>     But I don't think it's possible, correct?
>
>     -Piero
>
>
>
>     On 6/13/19 10:43 AM, Connor Manning wrote:
>>     The `subset` option lets each iteration of the build run a
>>     spatially distinct region, which can be trivially merged
>>     afterward, which sounds like what you're after.¬† Another option
>>     could be to simply use multiple indexes - potree can accept
>>     multiple input EPT sources, and a PDAL pipeline may have multiple
>>     EPT readers.
>>
>>     On Thu, Jun 13, 2019 at 6:46 AM Piero Toffanin
>>     <pt at masseranolabs.com <mailto:pt at masseranolabs.com>> wrote:
>>
>>         Hi there,
>>
>>         I have a question regarding the usage of Entwine and was
>>         hoping somebody could help me? The use case is merging point
>>         clouds that have been generated on different machines. Each
>>         of these point clouds is part to the same final dataset.
>>         Entwine works great with the current workflow:
>>
>>         entwine scan -i a.las b.las ... -o output/
>>
>>         for i in {a, b, ... }
>>
>>         ¬†¬†¬† entwine build -i output/scan.json -o output/ --run 1
>>
>>         The "--run 1" is done to lower the memory usage. On small
>>         datasets runtime is excellent, but with more models the
>>         runtime starts to increase quite a bit. I'm looking
>>         specifically to see if there are ways to speed the generation
>>         of the EPT index. In particular, since I generate the various
>>         LAS files on different machines, I was wondering if there was
>>         a way to let each machine contribute its part of the index
>>         from the individual LAS files (such index mapped to a network
>>         location) or if a workflow is supported in which each machine
>>         can build its own EPT index and then merge all EPT indexes
>>         into one? I don't think this is possible, but wanted to check.
>>
>>         Thank you for any help,
>>
>>         -Piero
>>
>>
>>         _______________________________________________
>>         pdal mailing list
>>         pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>
>>         https://lists.osgeo.org/mailman/listinfo/pdal
>>
>     -- 
>
>     *Piero Toffanin*
>     Drone Solutions Engineer
>
>     masseranolabs.com <https://www.masseranolabs.com>
>     piero.dev <https://www.piero.dev>
>
>
-- 

*Piero Toffanin*
Drone Solutions Engineer

masseranolabs.com <https://www.masseranolabs.com>
piero.dev <https://www.piero.dev>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190613/52c65285/attachment.html>

From adam.d.steer at gmail.com  Thu Jun 13 14:09:31 2019
From: adam.d.steer at gmail.com (adam steer)
Date: Fri, 14 Jun 2019 07:09:31 +1000
Subject: [pdal] Does Entwine support distributed builds?
In-Reply-To: <2d032f04-7c55-cf2d-e59e-4c15de23bff2@masseranolabs.com>
References: <47f8802a-e738-3326-ad69-afa2fb418d55@masseranolabs.com>
 <CAO=FyjLPi99vi4T02gaCUexSiWhc6UadmD0HZqeNAhadwQeCSQ@mail.gmail.com>
 <b0ee797b-2a96-f8a7-62dc-40a88c298d42@masseranolabs.com>
 <CAO=FyjJ8b8onyeebg2uhDkeOXu4azuH_05ZTLzxZ0Um4mKTs0g@mail.gmail.com>
 <2d032f04-7c55-cf2d-e59e-4c15de23bff2@masseranolabs.com>
Message-ID: <CAFORoyikfDgHR1svtOfcJR4k7qCS4B7G7dK0Qxysr6DO1GRCBA@mail.gmail.com>

Hi Piero

I'm watching your questions with interest - many have been on my mind also!

...did your second proposal (run 400 times) work?

that would, on the surface, use less memory since you're reading from one
las file at a time rather than (400/64) las files (potentially, assuming a
lot about how the data are distributed in space). ...but would also mean
partial writing of each entwine chunk, which will eventually contain data
from potentially (400/64) of your files...

...so the question there is 'can entwine support partial writing of
subsets'?



On Fri, 14 Jun 2019 at 01:57, Piero Toffanin <pt at masseranolabs.com> wrote:

> Thanks, suspected that was the case but wanted to confirm.
>
> In regard to building subsets, is there an advantage to using "entwine
> scan" vs. the input files directly to "entwine build" in terms of
> performance (or is scan a simple utility to simplify finding datasets
> within a folder)?
>
> Are there any tips or tricks that I should be aware of in terms of memory
> usage when building using subset? For example, is it memory efficient to do:
>
> entwine build -i 1.las 2.las [...] 399.las 400.las --subset 1 64 -o out1
>
> ?
>
> As compared to perhaps running 400 times:
>
> entwine build -i 1.las 2.las [...] 399.las 400.las --subset 1 64 -o out1
> --run 1
>
> ?
>
> Sorry for all the questions!
> On 6/13/19 11:39 AM, Connor Manning wrote:
>
> Correct - that is not possible.
>
> On Thu, Jun 13, 2019 at 10:16 AM Piero Toffanin <pt at masseranolabs.com>
> wrote:
>
> Hey Connor,
>
> thanks for the reply. I have looked at the subset option and I think it
> would work well for the case where I have already computed all the models.
> For example if I have a folder with:
>
> 1.las
> 2.las
> ...
>
> Then I could spin four machines and do:
>
> 1] entwine build -i 1.las 2.las --subset 1 4 -o out1
> 2] entwine build -i 1.las 2.las --subset 2 4 -o out2
> 3] entwine build -i 1.las 2.las --subset 3 4 -o out3
> 4] entwine build -i 1.las 2.las --subset 4 4 -o out4
>
> Then merge the results. I've noticed two things with this. It seemed that
> as the number of input files increased, the memory and time required to
> create each subset seemed increased also (that's why I opted to use scan +
> build --run 1). The second is that I need to wait for all point clouds to
> be available (both 1.las and 2.las need to be available before I can start
> processing them).
>
> I wanted to rule out whether it was possible to do something like (on two
> separate machines):
>
> 1] entwine build -i 1.las -o out1
> 2] entwine build -i 2.las -o out2
>
> And then merge the resulting EPT indexes into a "global" one:
>
> entwine merge -i out1 out2 -o merged
>
> But I don't think it's possible, correct?
>
> -Piero
>
>
> On 6/13/19 10:43 AM, Connor Manning wrote:
>
> The `subset` option lets each iteration of the build run a spatially
> distinct region, which can be trivially merged afterward, which sounds like
> what you're after.  Another option could be to simply use multiple indexes
> - potree can accept multiple input EPT sources, and a PDAL pipeline may
> have multiple EPT readers.
>
> On Thu, Jun 13, 2019 at 6:46 AM Piero Toffanin <pt at masseranolabs.com>
> wrote:
>
> Hi there,
>
> I have a question regarding the usage of Entwine and was hoping somebody
> could help me? The use case is merging point clouds that have been
> generated on different machines. Each of these point clouds is part to the
> same final dataset. Entwine works great with the current workflow:
>
> entwine scan -i a.las b.las ... -o output/
>
> for i in {a, b, ... }
>
>     entwine build -i output/scan.json -o output/ --run 1
>
> The "--run 1" is done to lower the memory usage. On small datasets runtime
> is excellent, but with more models the runtime starts to increase quite a
> bit. I'm looking specifically to see if there are ways to speed the
> generation of the EPT index. In particular, since I generate the various
> LAS files on different machines, I was wondering if there was a way to let
> each machine contribute its part of the index from the individual LAS files
> (such index mapped to a network location) or if a workflow is supported in
> which each machine can build its own EPT index and then merge all EPT
> indexes into one? I don't think this is possible, but wanted to check.
>
> Thank you for any help,
>
> -Piero
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
> --
>
> *Piero Toffanin*
> Drone Solutions Engineer
>
> masseranolabs.com <https://www.masseranolabs.com>
> piero.dev <https://www.piero.dev>
>
>
> --
>
> *Piero Toffanin*
> Drone Solutions Engineer
>
> masseranolabs.com <https://www.masseranolabs.com>
> piero.dev <https://www.piero.dev>
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Dr. Adam Steer
http://spatialised.net
https://www.researchgate.net/profile/Adam_Steer
http://au.linkedin.com/in/adamsteer
http://orcid.org/0000-0003-0046-7236
+61 427 091 712 ::  @adamdsteer

Suits are bad for business: http://www.spatialised.net/business-penguins/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190614/14f3542b/attachment.html>

From RPhillips at linz.govt.nz  Mon Jun 17 15:13:03 2019
From: RPhillips at linz.govt.nz (Rose Phillips)
Date: Mon, 17 Jun 2019 22:13:03 +0000
Subject: [pdal] Adding WKT string to LAS1.4 Point Format ID 6 File
Message-ID: <DB6C9333CF905C418FCA62058C67818904A326AF@prdassexch01.ad.linz.govt.nz>

Hi guys,

I have a question about manually adding a WKT string - EPSG:2193 + 7839 projection information to a LAS 1.4 Point Format ID 6 file.

I've tried these different methods and had the corresponding errors:-

Method One

Input (Command Line)
pdal translate --writers.las.a_srs="COMPD_CS["NZGD2000 / New Zealand Transverse Mercator 2000 + NZVD2016 height",PROJCS["NZGD2000 / New Zealand Transverse Mercator 2000",GEOGCS["NZGD2000",DATUM["New_Zealand_Geodetic_Datum_2000",SPHEROID["GRS 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6167"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4167"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",173],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",1600000],PARAMETER["false_northing",10000000],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AUTHORITY["EPSG","2193"]],VERT_CS["NZVD2016 height",VERT_DATUM["New Zealand Vertical Datum 2016",2005,AUTHORITY["EPSG","1169"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Up",UP],AUTHORITY["EPSG","7839"]]]" H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/CL2_BF44_2018_1000_4619.las H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/test_pdal_WKT.las --writers.las.forward="all"

Output
PDAL: Cannot determine reader for input file: /

Method Two (JSON)
pdal pipeline H:/RoseBackup/other_datasets/Gisbourne/wkt_2193_7839.json --readers.las.filename=H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/CL2_BF44_2018_1000_4619.las --writers.las.filename=H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/test_pdal_WKT.las

{
  "pipeline" : [
    {
                           "type" : "readers.las",
                           "filename" : "input.las"
    },
    {
                           "type" : "writers.las",
                           "minor_version" : 4,
                           "forward" : "all",
                           "a_srs" : "COMPD_CS["NZGD2000 / New Zealand Transverse Mercator 2000 + NZVD2016 height",PROJCS["NZGD2000 / New Zealand Transverse Mercator 2000",GEOGCS["NZGD2000",DATUM["New_Zealand_Geodetic_Datum_2000",SPHEROID["GRS 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6167"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4167"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",173],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",1600000],PARAMETER["false_northing",10000000],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AUTHORITY["EPSG","2193"]],VERT_CS["NZVD2016 height",VERT_DATUM["New Zealand Vertical Datum 2016",2005,AUTHORITY["EPSG","1169"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Up",UP],AUTHORITY["EPSG","7839"]]]",
                           "filename" : "output.las"

    }
 ]
}

Output
PDAL: JSON pipeline: Unable to parse pipeline:
* Line 10, Column 24
  Missing ',' or '}' in object declaration
----------------------------------------------------------------
Reference:-
http://osgeo-org.1560.x6.nabble.com/pdal-LAS-1-4-amp-WKT-vertical-coordinate-system-and-td5240123.html
----------------------------------------------------------------
I was wondering if you guys could point me in the direction where I've gone wrong?
Many thanks,
Rose Phillips

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190617/9fd175b9/attachment.html>

From andrew.bell.ia at gmail.com  Mon Jun 17 15:36:08 2019
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 17 Jun 2019 18:36:08 -0400
Subject: [pdal] Adding WKT string to LAS1.4 Point Format ID 6 File
In-Reply-To: <DB6C9333CF905C418FCA62058C67818904A326AF@prdassexch01.ad.linz.govt.nz>
References: <DB6C9333CF905C418FCA62058C67818904A326AF@prdassexch01.ad.linz.govt.nz>
Message-ID: <CACJ51z32vfN0ngpK4XOLfgJ4DUYw8is9746HY-g_h3gqE=Kshg@mail.gmail.com>

The problem is that your quotes aren't escaped, I think.

If all you're trying to do is replace an existing SRS (or fill one in where
it doesn't exist), you might just try:

pdal translate in.las out.las
--readers.las.spatialreference="EPSG:2193+7839" --writers.las.forward=all


On Mon, Jun 17, 2019 at 6:20 PM Rose Phillips <RPhillips at linz.govt.nz>
wrote:

> Hi guys,
>
>
>
> I have a question about manually adding a WKT string - EPSG:2193 + 7839
> projection information to a LAS 1.4 Point Format ID 6 file.
>
>
>
> I‚Äôve tried these different methods and had the corresponding errors:-
>
>
>
> Method One
>
>
>
> Input (Command Line)
>
> pdal translate --writers.las.a_srs="COMPD_CS["NZGD2000 / New Zealand
> Transverse Mercator 2000 + NZVD2016 height",PROJCS["NZGD2000 / New Zealand
> Transverse Mercator
> 2000",GEOGCS["NZGD2000",DATUM["New_Zealand_Geodetic_Datum_2000",SPHEROID["GRS
> 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6167"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4167"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",173],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",1600000],PARAMETER["false_northing",10000000],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AUTHORITY["EPSG","2193"]],VERT_CS["NZVD2016
> height",VERT_DATUM["New Zealand Vertical Datum
> 2016",2005,AUTHORITY["EPSG","1169"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Up",UP],AUTHORITY["EPSG","7839"]]]"
> H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/CL2_BF44_2018_1000_4619.las
> H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/test_pdal_WKT.las
> --writers.las.forward="all"
>
>
>
> Output
> PDAL: Cannot determine reader for input file: /
>
>
>
> Method Two (JSON)
>
> pdal pipeline H:/RoseBackup/other_datasets/Gisbourne/wkt_2193_7839.json
> --readers.las.filename=H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/CL2_BF44_2018_1000_4619.las
> --writers.las.filename=H:/RoseBackup/other_datasets/Gisbourne/test_wkt/original/test_pdal_WKT.las
>
>
>
> {
>
>   "pipeline" : [
>
>     {
>
>                            "type" : "readers.las",
>
>                            "filename" : "input.las"
>
>     },
>
>     {
>
>                            "type" : "writers.las",
>
>                            "minor_version" : 4,
>
>                            "forward" : "all",
>
>                            "a_srs" : "COMPD_CS["NZGD2000 / New Zealand
> Transverse Mercator 2000 + NZVD2016 height",PROJCS["NZGD2000 / New Zealand
> Transverse Mercator
> 2000",GEOGCS["NZGD2000",DATUM["New_Zealand_Geodetic_Datum_2000",SPHEROID["GRS
> 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6167"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","4167"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",0],PARAMETER["central_meridian",173],PARAMETER["scale_factor",0.9996],PARAMETER["false_easting",1600000],PARAMETER["false_northing",10000000],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AUTHORITY["EPSG","2193"]],VERT_CS["NZVD2016
> height",VERT_DATUM["New Zealand Vertical Datum
> 2016",2005,AUTHORITY["EPSG","1169"]],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["Up",UP],AUTHORITY["EPSG","7839"]]]",
>
>                            "filename" : "output.las"
>
>
>
>     }
>
>  ]
>
> }
>
>
>
> Output
>
> PDAL: JSON pipeline: Unable to parse pipeline:
>
> * Line 10, Column 24
>
>   Missing ',' or '}' in object declaration
>
> ----------------------------------------------------------------
>
> Reference:-
>
>
> http://osgeo-org.1560.x6.nabble.com/pdal-LAS-1-4-amp-WKT-vertical-coordinate-system-and-td5240123.html
>
> ----------------------------------------------------------------
>
> I was wondering if you guys could point me in the direction where I‚Äôve
> gone wrong?
>
> Many thanks,
>
> Rose Phillips
>
> ------------------------------
>
> This message contains information, which may be in confidence and may be
> subject to legal privilege. If you are not the intended recipient, you must
> not peruse, use, disseminate, distribute or copy this message. If you have
> received this message in error, please notify us immediately (Phone 0800
> 665 463 or info at linz.govt.nz) and destroy the original message. LINZ
> accepts no responsibility for changes to this email, or for any
> attachments, after its transmission from LINZ. Thank You.
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190617/98a2f14a/attachment-0001.html>

From steven.spiegel at slu.edu  Tue Jun 25 10:14:08 2019
From: steven.spiegel at slu.edu (Steven Spiegel)
Date: Tue, 25 Jun 2019 17:14:08 +0000
Subject: [pdal] pcl filtering
Message-ID: <DM6PR11MB3689F018526E274430671F749AE30@DM6PR11MB3689.namprd11.prod.outlook.com>

Good afternoon,

I just had a quick question on filtering with point cloud library.  In particular, I am currently working on tree segmentation in LiDAR data.  I've converted the data into a raster and conducted more traditional image segmentation methods (particularly watershed segmentation) however I would like to use more 3d segmentation algorithms.  Can I use any of the PCL algorithms with PDAL or is it only the ones listed in the documentation?  In particular, I wanted to use the cylindrical RANSAC (http://pointclouds.org/documentation/tutorials/cylinder_segmentation.php) to segment the tree trunk and branches.  Thank you!

Steven
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190625/a49f0637/attachment.html>

From brad.chambers at gmail.com  Wed Jun 26 04:14:41 2019
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Wed, 26 Jun 2019 06:14:41 -0500
Subject: [pdal] pcl filtering
In-Reply-To: <DM6PR11MB3689F018526E274430671F749AE30@DM6PR11MB3689.namprd11.prod.outlook.com>
References: <DM6PR11MB3689F018526E274430671F749AE30@DM6PR11MB3689.namprd11.prod.outlook.com>
Message-ID: <CAJyqqPyRqnhVzqhDxrEL2_8DOCxUymv8AZoHWdFS4zXWgsBhDg@mail.gmail.com>

Only the ones in the documentation are available at this time.

On Tue, Jun 25, 2019, 12:35 PM Steven Spiegel <steven.spiegel at slu.edu>
wrote:

> Good afternoon,
>
> I just had a quick question on filtering with point cloud library.  In
> particular, I am currently working on tree segmentation in LiDAR data.
> I've converted the data into a raster and conducted more traditional image
> segmentation methods (particularly watershed segmentation) however I would
> like to use more 3d segmentation algorithms.  Can I use any of the PCL
> algorithms with PDAL or is it only the ones listed in the documentation?
> In particular, I wanted to use the cylindrical RANSAC (
> http://pointclouds.org/documentation/tutorials/cylinder_segmentation.php)
> to segment the tree trunk and branches.  Thank you!
>
> Steven
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20190626/a23d409a/attachment.html>

